apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: hms-alert-rules
  namespace: monitoring
  labels:
    prometheus: k8s
    role: alert-rules
spec:
  groups:
  # System-level alerting rules
  - name: node.rules
    rules:
    - alert: HighNodeCPUUsage
      expr: avg by(instance) (rate(node_cpu_seconds_total{mode!="idle"}[5m])) * 100 > 85
      for: 10m
      labels:
        severity: warning
        category: system
      annotations:
        summary: "High CPU usage on {{ $labels.instance }}"
        description: "CPU usage is above 85% for more than 10 minutes. Current value: {{ $value }}%"
        runbook_url: "https://runbooks.hms.health/high-cpu-usage"
        
    - alert: HighNodeMemoryUsage
      expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
      for: 10m
      labels:
        severity: warning
        category: system
      annotations:
        summary: "High memory usage on {{ $labels.instance }}"
        description: "Memory usage is above 90% for more than 10 minutes. Current value: {{ $value }}%"
        runbook_url: "https://runbooks.hms.health/high-memory-usage"
        
    - alert: NodeDiskSpaceCritical
      expr: node_filesystem_avail_bytes{mountpoint="/"}  / node_filesystem_size_bytes{mountpoint="/"} * 100 < 10
      for: 5m
      labels:
        severity: critical
        category: system
      annotations:
        summary: "Critical disk space on {{ $labels.instance }}:{{ $labels.mountpoint }}"
        description: "Disk space usage is above 90%. Current value: {{ $value }}%"
        runbook_url: "https://runbooks.hms.health/disk-space-critical"
        
  # Kubernetes-level alerting rules
  - name: kubernetes.rules
    rules:
    - alert: KubePodCrashLooping
      expr: rate(kube_pod_container_status_restarts_total{namespace=~"hms|security|monitoring"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
        category: kubernetes
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting {{ $value }} times / 5 minutes"
        runbook_url: "https://runbooks.hms.health/pod-crash-looping"
        
    - alert: KubePodNotReady
      expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown"}) > 0
      for: 15m
      labels:
        severity: warning
        category: kubernetes
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for more than 15 minutes"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for more than 15 minutes"
        runbook_url: "https://runbooks.hms.health/pod-not-ready"
        
    - alert: KubeDeploymentReplicasMismatch
      expr: kube_deployment_spec_replicas{namespace=~"hms|security"} != kube_deployment_status_replicas_available{namespace=~"hms|security"}
      for: 15m
      labels:
        severity: warning
        category: kubernetes
      annotations:
        summary: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas"
        description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes"
        runbook_url: "https://runbooks.hms.health/deployment-replicas-mismatch"
        
  # Application-level alerting rules
  - name: application.rules
    rules:
    - alert: APIHighLatency
      expr: http_request_duration_seconds{quantile="0.95",job=~".*api.*"} > 0.5
      for: 5m
      labels:
        severity: warning
        category: application
        team: backend
      annotations:
        summary: "High API latency for {{ $labels.handler }}"
        description: "95th percentile of HTTP request duration is above 500ms for {{ $labels.handler }}. Current value: {{ $value }}s"
        runbook_url: "https://runbooks.hms.health/api-high-latency"
        
    - alert: APIErrorRate
      expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (job, handler) / sum(rate(http_requests_total[5m])) by (job, handler) > 0.05
      for: 5m
      labels:
        severity: critical
        category: application
        team: backend
      annotations:
        summary: "High error rate for {{ $labels.job }}/{{ $labels.handler }}"
        description: "Error rate is above 5% for {{ $labels.job }}/{{ $labels.handler }}. Current value: {{ $value | humanizePercentage }}"
        runbook_url: "https://runbooks.hms.health/api-error-rate"
        
    - alert: FrontendJSErrors
      expr: sum(increase(frontend_js_errors_total[5m])) > 10
      for: 5m
      labels:
        severity: warning
        category: application
        team: frontend
      annotations:
        summary: "High number of frontend JavaScript errors"
        description: "More than 10 JavaScript errors in the frontend in the last 5 minutes. Current count: {{ $value }}"
        runbook_url: "https://runbooks.hms.health/frontend-js-errors"
        
  # Database-level alerting rules
  - name: database.rules
    rules:
    - alert: PostgresqlHighConnections
      expr: sum by (instance) (pg_stat_activity_count) > pg_settings_max_connections * 0.8
      for: 5m
      labels:
        severity: warning
        category: database
        team: dba
      annotations:
        summary: "High number of PostgreSQL connections on {{ $labels.instance }}"
        description: "PostgreSQL instance has more than 80% of its connection limit. Current connections: {{ $value }}"
        runbook_url: "https://runbooks.hms.health/postgres-high-connections"
        
    - alert: PostgresqlSlowQueries
      expr: rate(pg_stat_activity_max_tx_duration{datname=~"hms.*"}[5m]) > 30
      for: 5m
      labels:
        severity: warning
        category: database
        team: dba
      annotations:
        summary: "Slow PostgreSQL queries on {{ $labels.instance }}"
        description: "PostgreSQL instance has queries running for more than 30 seconds. Max query duration: {{ $value }}s"
        runbook_url: "https://runbooks.hms.health/postgres-slow-queries"
        
    - alert: PostgresqlReplicationLag
      expr: pg_replication_lag > 300
      for: 1m
      labels:
        severity: critical
        category: database
        team: dba
      annotations:
        summary: "PostgreSQL replication lag on {{ $labels.instance }}"
        description: "PostgreSQL replication is lagging by more than 5 minutes. Current lag: {{ $value }}s"
        runbook_url: "https://runbooks.hms.health/postgres-replication-lag"
        
  # Redis-level alerting rules
  - name: redis.rules
    rules:
    - alert: RedisHighMemoryUsage
      expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 85
      for: 5m
      labels:
        severity: warning
        category: cache
        team: infrastructure
      annotations:
        summary: "High Redis memory usage on {{ $labels.instance }}"
        description: "Redis memory usage is above 85%. Current value: {{ $value | humanizePercentage }}"
        runbook_url: "https://runbooks.hms.health/redis-high-memory"
        
    - alert: RedisKeyEvictions
      expr: rate(redis_evicted_keys_total[5m]) > 0
      for: 5m
      labels:
        severity: warning
        category: cache
        team: infrastructure
      annotations:
        summary: "Redis key evictions occurring on {{ $labels.instance }}"
        description: "Redis is evicting keys due to memory pressure. Rate: {{ $value }} keys/s"
        runbook_url: "https://runbooks.hms.health/redis-evictions"
        
  # Business-level alerting rules
  - name: business.rules
    rules:
    - alert: HighAppointmentCancellationRate
      expr: sum(increase(appointments_cancelled_total[1h])) / sum(increase(appointments_created_total[1h])) > 0.2
      for: 1h
      labels:
        severity: warning
        category: business
        team: operations
      annotations:
        summary: "High appointment cancellation rate"
        description: "More than 20% of appointments are being cancelled. Current rate: {{ $value | humanizePercentage }}"
        runbook_url: "https://runbooks.hms.health/high-cancellation-rate"
        
    - alert: LowPharmacyInventory
      expr: min by(medication) (pharmacy_inventory_count) < pharmacy_inventory_min_threshold
      for: 5m
      labels:
        severity: warning
        category: business
        team: pharmacy
      annotations:
        summary: "Low inventory for {{ $labels.medication }}"
        description: "Pharmacy inventory for {{ $labels.medication }} is below threshold. Current count: {{ $value }}"
        runbook_url: "https://runbooks.hms.health/low-pharmacy-inventory"
        
    - alert: HighERWaitTime
      expr: avg_over_time(er_wait_time_minutes[1h]) > 60
      for: 30m
      labels:
        severity: critical
        category: clinical
        team: emergency
      annotations:
        summary: "High ER wait time"
        description: "Average ER wait time is above 60 minutes for the past 30 minutes. Current average: {{ $value }} minutes"
        runbook_url: "https://runbooks.hms.health/high-er-wait-time"
        
  # Security-level alerting rules
  - name: security.rules
    rules:
    - alert: HighLoginFailureRate
      expr: sum(rate(login_failures_total[5m])) / sum(rate(login_attempts_total[5m])) > 0.3
      for: 5m
      labels:
        severity: critical
        category: security
        team: security
      annotations:
        summary: "High login failure rate"
        description: "More than 30% of login attempts are failing. Current rate: {{ $value | humanizePercentage }}"
        runbook_url: "https://runbooks.hms.health/high-login-failure-rate"
        
    - alert: UnusualAccessPatterns
      expr: sum(rate(api_access_unusual_pattern_total[5m])) > 10
      for: 5m
      labels:
        severity: critical
        category: security
        team: security
      annotations:
        summary: "Unusual API access patterns detected"
        description: "Security system has detected unusual API access patterns. Count: {{ $value }} in the last 5 minutes"
        runbook_url: "https://runbooks.hms.health/unusual-access-patterns"
        
    - alert: SensitiveDataAccess
      expr: sum(rate(phi_data_access_total{authorized="false"}[5m])) > 0
      for: 1m
      labels:
        severity: critical
        category: security
        team: security
      annotations:
        summary: "Unauthorized sensitive data access detected"
        description: "Unauthorized access to PHI/PII data has been detected. Access count: {{ $value }} in the last 5 minutes"
        runbook_url: "https://runbooks.hms.health/unauthorized-phi-access"